{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetectionInVideo_UsingYoloWithKeras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNNw0zdtmUAe",
        "colab_type": "text"
      },
      "source": [
        "#### Importing required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cbWDUMhhlv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d7ffb30-dd97-4d67-e566-1d94191aa6e2"
      },
      "source": [
        "import struct\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model\n",
        "from keras import backend as k\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4xvdv-f2Ftu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcU53N0gmkBy",
        "colab_type": "text"
      },
      "source": [
        "### Defining mandatory fuction.\n",
        "* Bounding box \n",
        "* Get the Label from prediction\n",
        "* Get the class score\n",
        "* Class wise sepparation of output boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3BVgOq92HXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BoundBox:\n",
        "\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "\t\tself.xmin = xmin\n",
        "\t\tself.ymin = ymin\n",
        "\t\tself.xmax = xmax\n",
        "\t\tself.ymax = ymax\n",
        "\t\tself.objness = objness\n",
        "\t\tself.classes = classes\n",
        "\t\tself.label = -1\n",
        "\t\tself.score = -1\n",
        " \n",
        "\tdef get_label(self):\n",
        "\t\tif self.label == -1:\n",
        "\t\t\tself.label = np.argmax(self.classes)\n",
        " \n",
        "\t\treturn self.label\n",
        " \n",
        "\tdef get_score(self):\n",
        "\t\tif self.score == -1:\n",
        "\t\t\tself.score = self.classes[self.get_label()]\n",
        " \n",
        "\t\treturn self.score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGVYKp6m2K81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _sigmoid(x):\n",
        "\treturn 1. / (1. + np.exp(-x))\n",
        " \n",
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "\tgrid_h, grid_w = netout.shape[:2]\n",
        "\tnb_box = 3\n",
        "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "\tnb_class = netout.shape[-1] - 5\n",
        "\tboxes = []\n",
        "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        " \n",
        "\tfor i in range(grid_h*grid_w):\n",
        "\t\trow = i / grid_w\n",
        "\t\tcol = i % grid_w\n",
        "\t\tfor b in range(nb_box):\n",
        "\t\t\t# 4th element is objectness score\n",
        "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
        "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
        "\t\t\t# first 4 elements are x, y, w, and h\n",
        "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "\t\t\tx = (col + x) / grid_w # center position, unit: image width\n",
        "\t\t\ty = (row + y) / grid_h # center position, unit: image height\n",
        "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
        "\t\t\t# last elements are class probabilities\n",
        "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
        "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "\t\t\tboxes.append(box)\n",
        "\treturn boxes\n",
        " \n",
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "\tnew_w, new_h = net_w, net_h\n",
        "\tfor i in range(len(boxes)):\n",
        "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        " \n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "\tx1, x2 = interval_a\n",
        "\tx3, x4 = interval_b\n",
        "\tif x3 < x1:\n",
        "\t\tif x4 < x1:\n",
        "\t\t\treturn 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x1\n",
        "\telse:\n",
        "\t\tif x2 < x3:\n",
        "\t\t\t return 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi9BaFzmnCEp",
        "colab_type": "text"
      },
      "source": [
        "* IOU and NMS classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ17NEA32Ot7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bbox_iou(box1, box2):\n",
        "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\tintersect = intersect_w * intersect_h\n",
        "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\tunion = w1*h1 + w2*h2 - intersect\n",
        "\treturn float(intersect) / union\n",
        " \n",
        "def do_nms(boxes, nms_thresh):\n",
        "\tif len(boxes) > 0:\n",
        "\t\tnb_class = len(boxes[0].classes)\n",
        "\telse:\n",
        "\t\treturn\n",
        "\tfor c in range(nb_class):\n",
        "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\t\tfor i in range(len(sorted_indices)):\n",
        "\t\t\tindex_i = sorted_indices[i]\n",
        "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
        "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
        "\t\t\t\tindex_j = sorted_indices[j]\n",
        "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "\t\t\t\t\tboxes[index_j].classes[c] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-XC65OH2SVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load and prepare an image\n",
        "def load_image_pixels(filename, shape):\n",
        "\t# load the image to get its shape\n",
        "\twidth, height = filename.size\n",
        "\t# load the image with the required size\n",
        "\timage = filename.resize(shape)\n",
        "\t# convert to numpy array\n",
        "\timage = img_to_array(image)\n",
        "\timage = image.astype('float32')\n",
        "\timage /= 255.0\n",
        "\t# add a dimension so that we have one sample\n",
        "\timage = expand_dims(image, 0)\n",
        "\treturn image, width, height"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5eDNjDv2VVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get all of the results above a threshold\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
        "\t# enumerate all boxes\n",
        "\tfor box in boxes:\n",
        "\t\t# enumerate all possible labels\n",
        "\t\tfor i in range(len(labels)):\n",
        "\t\t\t# check if the threshold for this label is high enough\n",
        "\t\t\tif box.classes[i] > thresh:\n",
        "\t\t\t\tv_boxes.append(box)\n",
        "\t\t\t\tv_labels.append(labels[i])\n",
        "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
        "\t\t\t\t# don't break, many labels may trigger for one box\n",
        "\treturn v_boxes, v_labels, v_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-RIN37unHyE",
        "colab_type": "text"
      },
      "source": [
        "## Class to draw the final boxes in the frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go8EUZIo2ZOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# draw all results\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "\timage = filename\n",
        "\t# plot each box\n",
        "\tfor i in range(len(v_boxes)):\n",
        "\t\tbox = v_boxes[i]\n",
        "\t\t# get coordinates\n",
        "\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "\t\t# create the shape\n",
        "\t\timage = cv2.rectangle(image, (x1, y1), (x2,y2), (36,255,12), 2)\n",
        "\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
        "\t\timage= cv2.putText(image, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2) \n",
        "\treturn image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIhA-yl9q8go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
        "\n",
        "class_threshold = 0.6\n",
        "\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
        "\t\"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
        "\t\"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
        "\t\"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
        "\t\"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
        "\t\"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
        "\t\"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
        "\t\"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
        "\t\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
        "\t\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u7wAeH7MEwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load yolov3 model\n",
        "model = load_model('ObjectDetectionInVideo/model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdH3dOo0UNDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl7sc2lknPad",
        "colab_type": "text"
      },
      "source": [
        "## Reading all the frames in a List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqfGa-gM_wr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap = cv2.VideoCapture('ObjectDetectionInVideo/Sample.mov')\n",
        "frames = []\n",
        "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print( length )\n",
        "\n",
        "while(cap.isOpened()):\n",
        "  length = length -1\n",
        "  print(length)\n",
        "  ret, frame = cap.read()\n",
        "  if ret == True:\n",
        "    # load and prepare image\n",
        "    frames.append(frame)\n",
        "  else:\n",
        "    break\n",
        "\n",
        "\n",
        "cap.release()\n",
        "# Closes all the frames\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKepVANSnWkq",
        "colab_type": "text"
      },
      "source": [
        "## Frame by frame processing and drawing predicted boxes on the frame along with the label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZTOMekh2eeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Out_frames=[]\n",
        "\n",
        "for i1 in range(228,len(frames)):\n",
        "\tprint(i1)\n",
        "\t# load and prepare image\n",
        "\tframe =frames[i1]\n",
        "\tframes[i1] = None\n",
        "\ttempImage = Image.fromarray(frame)\n",
        "\timage, image_w, image_h = load_image_pixels(tempImage, (416, 416))\n",
        "\t# make prediction\n",
        "\tyhat = model.predict(image)\n",
        "\t# summarize the shape of the list of arrays\n",
        "\tboxes = list()\n",
        "\tfor i in range(len(yhat)):\n",
        "\t\tboxes += decode_netout(yhat[i][0], anchors[i], class_threshold, 416, 416)\n",
        "\t \t# correct the sizes of the bounding boxes for the shape of the image\n",
        "\t\tcorrect_yolo_boxes(boxes, image_h, image_w, 416, 416)\n",
        "\t\t# suppress non-maximal boxes\n",
        "\t\tdo_nms(boxes, 0.5)\n",
        "\t\t# get the details of the detected objects\n",
        "\t\tv_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
        "\t\t# draw what we found\n",
        "\t\toutput= draw_boxes(frame, v_boxes, v_labels, v_scores)\n",
        "\t\tOut_frames.append(np.array(output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgDyBSuPnhwm",
        "colab_type": "text"
      },
      "source": [
        "### Writing the frames in a AVI output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viIZ2DSjNbZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = cv2.VideoWriter('ObjectDetectionInVideo/Result.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 23, (848,360))\n",
        "check = 0\n",
        "for frame in Out_frames:\n",
        "  check = check + 1\n",
        "  print(check)\n",
        "  out.write(frame)\n",
        "\n",
        "out.release() \n",
        "cv2.destroyAllWindows() "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}