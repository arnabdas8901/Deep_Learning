{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Cats vs Dogs classifier using resnet\nInspired by resnet50 Architecture. But not using pretrained weights."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imports\nimport keras\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')\nK.set_learning_phase(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Section to unzip data file."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Unzip zipped data set\nfrom zipfile import ZipFile\nwith ZipFile('/kaggle/input/dogs-vs-cats/train.zip','r') as zip:\n    zip.extractall('/kaggle/working')\nwith ZipFile('/kaggle/input/dogs-vs-cats/test1.zip','r') as zip:\n    zip.extractall('/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Section for creating necessary directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Storing Cats and dogs training images in respective folder.\n%mkdir /kaggle/working/train/Cat\n%mv /kaggle/working/train/cat* /kaggle/working/train/Cat/\n%mkdir /kaggle/working/train/Dog\n%mv /kaggle/working/train/dog* /kaggle/working/train/Dog/\n%mkdir /kaggle/working/test1/test\n%mv -f /kaggle/working/test1/*.jpg /kaggle/working/test1/test/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"taining_data = '/kaggle/working/train'\ntest_data = '/kaggle/working/test1'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating trainign batch from images"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_batch = ImageDataGenerator(rescale=1./255).flow_from_directory(taining_data, target_size=(256, 256), color_mode='rgb', class_mode='categorical', batch_size=32)\ntest_batch = ImageDataGenerator(rescale=1./255).flow_from_directory(test_data, target_size=(256, 256), color_mode='rgb', class_mode=None, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def identity_block(X, f, filters):\n    F1, F2, F3 = filters\n    \n    X_skip = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n    \n    \n    # Second component of main path \n    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n    X = Add()([X,X_skip])\n    X = Activation('relu')(X)\n    \n    ### END CODE HERE ###\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convolutional_block(X, f, filters, s = 2):\n    \n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_skip = X\n\n    # First component of main path \n    X = Conv2D(F1, (1, 1), strides = (s,s), kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n    \n\n    # Second component of main path\n    X = Conv2D(F2, (f, f), strides = (1,1), padding='same', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path\n    X = Conv2D(F3, (1, 1), strides = (1,1), padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n\n    X_skip = Conv2D(F3, (1, 1), strides = (s,s), padding='valid', kernel_initializer = glorot_uniform(seed=0))(X_skip)\n    X_skip = BatchNormalization(axis = 3)(X_skip)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n    X = Add()([X,X_skip])\n    X = Activation('relu')(X)\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ResNetModel(input_shape):\n\n    \n    # Define the input as a tensor with shape input_shape\n    X_input = Input(input_shape)\n\n    \n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis = 3)(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n    X = identity_block(X, 3, [64, 64, 256])\n    X = identity_block(X, 3, [64, 64, 256])\n\n    # Stage 3\n    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n    X = identity_block(X, 3, [128, 128, 512])\n    X = identity_block(X, 3, [128, 128, 512])\n    X = identity_block(X, 3, [128, 128, 512])\n\n    # AVGPOOL\n    X = AveragePooling2D(pool_size=(2, 2), name='avg_pool')(X)\n    #MAXPool\n    \n    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n\n    # output layer\n    X = Flatten()(X)\n    X = Dense(128, activation='relu', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = Dense(128, activation='relu', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = Dense(2, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n    \n    \n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='ResNetModel')\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"myClassifier = ResNetModel((256, 256, 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Input size for this model is 256x256x3"},{"metadata":{"trusted":true},"cell_type":"code","source":"myClassifier.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"myClassifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"myClassifier.fit(training_batch, epochs = 40, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"myClassifier.save('/kaggle/working/CatsVsDogs_resnet_Custom.h5')\nmyClassifier.save_weights('/kaggle/working/CatsVsDogs_resnet_Custom_weghts.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Saving output"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nimport csv\n\ndirectory = '/kaggle/working/test1/test'\n\nwith open('mySubmision.csv', 'w', newline='') as op:\n    myWritter = csv.writer(op)\n    myWritter.writerow(['id','label'])\n    for filename in os.listdir(directory):\n        img = image.load_img(os.path.join(directory,filename), target_size=(256, 256))\n        x = image.img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        x = x/255.0\n        id = filename.split('.')[0]\n        prediction = np.argmax(myClassifier.predict(x))\n        myWritter.writerow([id,prediction])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}